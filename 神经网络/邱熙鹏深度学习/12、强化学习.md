## 1. 马尔科夫过程 (Markov Process)
- **定义**: 一种随机过程，其未来状态只依赖于当前状态，而与过去的状态无关（无后效性）。
  
$$
P(X_{t+1} | X_t, X_{t-1}, \dots, X_0) = P(X_{t+1} | X_t)
$$

---

## 2. 马尔科夫链 (Markov Chain)
- **转移概率矩阵**:

$$
P = 
\begin{bmatrix}
P_{11} & P_{12} & \dots & P_{1n} \\
P_{21} & P_{22} & \dots & P_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
P_{n1} & P_{n2} & \dots & P_{nn}
\end{bmatrix}
$$

其中 $ P_{ij} = P(X_{t+1}=j | X_t=i) $。

---

## 3. 隐马尔科夫模型 (Hidden Markov Model, HMM)
- **组成部分**:
  - 初始状态概率:
  
  $$
  \pi_i = P(X_0 = i)
  $$

  - 状态转移概率:

  $$
  A_{ij} = P(X_{t+1}=j | X_t=i)
  $$

  - 观测概率:

  $$
  B_{ij} = P(O_t = o_j | X_t = i)
  $$

- **目标函数**:
  评估观测序列的概率：

  $$
  P(O | \lambda) = \sum_{X} P(O, X | \lambda)
  $$

---

## 4. 马尔科夫决策过程 (Markov Decision Process, MDP)
- **折扣奖励的累积形式**:

$$
G_t = R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + \dots = \sum_{k=0}^\infty \gamma^k R_{t+k}
$$

- **贝尔曼方程**:
  
  对于状态值函数 $ V(s) $:

  $$
  V(s) = \max_a \sum_{s'} P(s' | s, a) \left[ R(s, a) + \gamma V(s') \right]
  $$

---

## 5. 马尔科夫随机场 (Markov Random Field, MRF)
- **联合概率分布**:

$$
P(X_1, X_2, \dots, X_n) = \frac{1}{Z} \prod_{C \in \text{cliques}} \psi_C(X_C)
$$

其中 $ \psi_C(X_C) $ 是团势函数，$ Z $ 是归一化常数。

---

## 6. 马尔科夫链蒙特卡罗方法 (Markov Chain Monte Carlo, MCMC)
- **详细平衡条件**:

$$
\pi(i)P_{ij} = \pi(j)P_{ji}
$$

---

## 7. 马尔科夫模型的重要概念

### **无后效性 (Markov Property)**

$$
P(X_{t+1} | X_t, X_{t-1}, \dots, X_0) = P(X_{t+1} | X_t)
$$

### **平稳分布 (Stationary Distribution)**

$$
\pi P = \pi
$$

### **累积奖励的定义**:

$$
G_t = R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + \dots
$$

### **混合时间 (Mixing Time)**

指马尔科夫链达到平稳分布所需的时间，没有具体公式。

---

## 8. 隐马尔科夫模型的解码问题

- **维特比算法**:

$$
\delta_t(i) = \max_{j} \left[ \delta_{t-1}(j) A_{ji} \right] B_{i}(O_t)
$$

其中 $ \delta_t(i) $ 是最优路径的概率。

---

## 总结
本文总结了马尔科夫模型的核心公式与概念，涵盖了马尔科夫链、隐马尔科夫模型、马尔科夫决策过程等的关键内容。