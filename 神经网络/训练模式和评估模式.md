在进行深度学习PyTorch实战的过程中，我们时常需要在训练和评估两种模式间切换。训练模式对应了模型的学习阶段，评估模式则是为了检验模型的性能。在PyTorch中，我们通过调用`model.train()`和`model.eval()`来实现这种切换。这两个方法的使用至关重要，因为它们会影响到某些层的运作方式，例如`Dropout`和`BatchNorm`。所以，理解并恰当运用这两个方法，对模型的优化至关重要。

| 模式                        | 前向传播 | 反向传播 | 参数更新 | Dropout 层行为                       | BatchNorm 层行为                                   |
| --------------------------- | -------- | -------- | -------- | ------------------------------------ | -------------------------------------------------- |
| 训练模式（Training Mode）   | 是       | 是       | 是       | 随机将一部分神经元关闭，以防止过拟合 | 使用每一批数据的均值和方差进行归一化处理           |
| 评估模式（Evaluation Mode） | 是       | 否       | 否       | 关闭所有神经元，不再进行随机舍弃     | 使用在训练阶段计算得到的全局统计数据进行归一化处理 |

训练模式（Training Mode）：如表格所示，在此模式下，模型会进行前向传播、反向传播以及参数更新。某些层，如Dropout层和BatchNorm层，在此模式下的行为会与评估模式下不同。例如，Dropout层会在训练过程中随机将一部分输入设置为0，以防止过拟合。
评估模式（Evaluation Mode）：如表格所示，在此模式下，模型只会进行前向传播，不会进行反向传播和参数更新。Dropout层会停止dropout，BatchNorm层会使用在训练阶段计算得到的全局统计数据，而不是测试集中的批统计数据。

## 在实战中使用model.train()和model.eval()

在PyTorch实战中，你可以通过以下方式将模型设置为训练模式或评估模式：

```python
# 将模型设置为训练模式
model.train()

# 将模型设置为评估模式
model.eval()
```

训练模式 vs 评估模式

```python
import torch
import torch.nn as nn
import torch.optim as optim

# 定义一个简单的模型
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(10, 10)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(10, 1)
        self.dropout = nn.Dropout(0.5)
        
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)  # 在训练和评估阶段行为不同
        x = self.fc2(x)
        return x

# 初始化模型、优化器和损失函数
model = SimpleModel()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.MSELoss()

# 假设我们有一些训练数据和测试数据
train_data = torch.randn((100, 10))  # 训练数据，大小为(100, 10)
train_labels = torch.randn((100, 1))  # 训练标签，大小为(100, 1)
test_data = torch.randn((20, 10))  # 测试数据，大小为(20, 10)
test_labels = torch.randn((20, 1))  # 测试标签，大小为(20, 1)

# 训练阶段
model.train()  # 设置模型为训练模式
for epoch in range(10):  # 进行10个epoch的训练
    optimizer.zero_grad()  # 清空之前的梯度信息（如果有的话）
    outputs = model(train_data)  # 前向传播
    loss = criterion(outputs, train_labels)  # 计算损失
    loss.backward()  # 反向传播，计算梯度
    optimizer.step()  # 更新权重参数
    print(f'Epoch {epoch+1}, Loss: {loss.item()}')  # 打印损失信息

# 评估阶段
model.eval()  # 设置模型为评估模式
with torch.no_grad():  # 确保不会进行反向传播计算梯度，节省内存和计算资源
    test_outputs = model(test_data)  # 前向传播获取测试集的预测结果
    test_loss = criterion(test_outputs, test_labels)  # 计算测试集上的损失值
    print(f'Test Loss: {test_loss.item()}')  # 打印测试损失信息

```

- requires_grad一定要等于True，不然无法构建计算图
- 非叶子节点在required_grad=True的时候也不会主动计算，你想计算需要使用tensor.retain_grad()函数
- 通过张量的 `grad_fn` 属性来检查它的计算历史。`grad_fn` 表示创建该张量的函数，只有当张量是通过某些操作得到的中间张量时，`grad_fn` 才不为 None。
- 反向传播之后不能再进行反向传播：如果你想在同一图中进行多次反向传播，需要在第一次调用时使用 `retain_graph=True` 参数。这会告诉 PyTorch 保留计算图的中间结果，以便后续可以进行更多的反向传播。因为此时的计算图已经释放了。
- 累计梯度，会在同一个batch下进行，输入的到底是batch还是batch中的一条数据有待考证
- 在 PyTorch 中，调用 `loss.backward()` 会将当前计算得到的梯度加到每个参数的 `.grad` 属性中，而不是直接覆盖它。这种行为允许在某些情况下（例如，使用小批量数据进行多次前向传播）对梯度进行累积。